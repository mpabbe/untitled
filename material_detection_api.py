from flask import Flask, request, jsonify
import cv2
import numpy as np
import pytesseract
import re
from PIL import Image, ImageEnhance, ImageFilter
import requests
from io import BytesIO
import easyocr
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration, CLIPProcessor, CLIPModel
from ultralytics import YOLO
import base64
import json
from collections import defaultdict
import math

app = Flask(__name__)

# AI Models ni yuklash
print("Loading enhanced AI models...")
reader = easyocr.Reader(['ru'])

# BLIP model for image understanding
blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# CLIP model for better classification
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")

# YOLO model for object detection
yolo_model = YOLO('yolov8n.pt')

print("Enhanced AI models loaded successfully!")

# Kolodets (well) uchun maxsus material patterns
KOLODETS_MATERIALS = {
    'concrete_rings': {
        'patterns': [
            r'–∫–æ–ª—å—Ü–æ\s*(?:–∫—Å|–∂–±–∏|–±–µ—Ç–æ–Ω–Ω–æ–µ)?\s*(\d+)[-.]?(\d+)?',
            r'–∫—Å[-]?(\d+)[-.]?(\d+)?',
            r'–∂–±–∏\s*–∫–æ–ª—å—Ü–æ\s*(\d+)[-.]?(\d+)?',
            r'–±–µ—Ç–æ–Ω–Ω–æ–µ\s*–∫–æ–ª—å—Ü–æ\s*(\d+)x(\d+)',
            r'ring\s*(\d+)[-.]?(\d+)?',
            r'concrete\s*ring\s*(\d+)[-.]?(\d+)?',
        ],
        'keywords': ['–∫–æ–ª—å—Ü–æ', '–∫—Å', '–∂–±–∏', '–±–µ—Ç–æ–Ω–Ω–æ–µ –∫–æ–ª—å—Ü–æ', 'ring', 'concrete ring'],
        'sizes': ['10-9', '15-9', '20-9', '10-6', '15-6', '20-6'],
        'unit': '–¥–æ–Ω–∞',
        'category': 'concrete_elements'
    },
    'concrete_covers': {
        'patterns': [
            r'–∫—Ä—ã—à–∫–∞\s*(?:–∫—Å|–∂–±–∏|–±–µ—Ç–æ–Ω–Ω–∞—è)?\s*(\d+)',
            r'–ø–ª–∏—Ç–∞\s*(?:–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è|–∫—Ä—ã—à–∫–∞)?\s*(\d+)',
            r'–ø–∫—Å[-]?(\d+)',
            r'cover\s*(\d+)',
            r'lid\s*(\d+)',
        ],
        'keywords': ['–∫—Ä—ã—à–∫–∞', '–ø–ª–∏—Ç–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è', '–ø–∫—Å', 'cover', 'lid'],
        'sizes': ['10', '15', '20'],
        'unit': '–¥–æ–Ω–∞',
        'category': 'concrete_elements'
    },
    'bottom_plates': {
        'patterns': [
            r'–ø–ª–∏—Ç–∞\s*(?:–¥–Ω–∏—â–∞|–¥–Ω–∞|–æ–ø–æ—Ä–Ω–∞—è)?\s*(\d+)',
            r'–ø–¥[-]?(\d+)',
            r'–æ–ø–æ—Ä–Ω–∞—è\s*–ø–ª–∏—Ç–∞\s*(\d+)',
            r'bottom\s*plate\s*(\d+)',
        ],
        'keywords': ['–ø–ª–∏—Ç–∞ –¥–Ω–∏—â–∞', '–ø–¥', '–æ–ø–æ—Ä–Ω–∞—è –ø–ª–∏—Ç–∞', 'bottom plate'],
        'sizes': ['10', '15', '20'],
        'unit': '–¥–æ–Ω–∞',
        'category': 'concrete_elements'
    },
    'pipes': {
        'patterns': [
            r'—Ç—Ä—É–±–∞\s*(?:–ø–Ω–¥|–ø—ç|—Å—Ç–∞–ª—å–Ω–∞—è|–º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∞—è|–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω–∞—è)?\s*(?:√∏|d|–¥–∏–∞–º–µ—Ç—Ä)?\s*(\d+)(?:\s*–º–º)?',
            r'–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω–∞—è\s*—Ç—Ä—É–±–∞\s*(?:√∏|d)?\s*(\d+)',
            r'—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥\s*(?:√∏|d)?\s*(\d+)',
            r'pipe\s*(?:√∏|d)?\s*(\d+)',
            r'quvur\s*(?:√∏|d)?\s*(\d+)',
        ],
        'keywords': ['—Ç—Ä—É–±–∞', '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω–∞—è —Ç—Ä—É–±–∞', '—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥', 'pipe', 'quvur'],
        'sizes': ['50', '63', '75', '90', '110', '125', '160', '200'],
        'unit': '–º–µ—Ç—Ä',
        'category': 'pipes'
    },
    'fittings': {
        'patterns': [
            r'–º—É—Ñ—Ç–∞\s*(?:—Å–æ–µ–¥–∏–Ω–∏—Ç–µ–ª—å–Ω–∞—è|–ø–Ω–¥)?\s*(?:√∏|d)?\s*(\d+)',
            r'—Ç—Ä–æ–π–Ω–∏–∫\s*(?:–ø–Ω–¥|–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω—ã–π)?\s*(?:√∏|d)?\s*(\d+)(?:x(\d+))?',
            r'–æ—Ç–≤–æ–¥\s*(?:90¬∞|45¬∞)?\s*(?:√∏|d)?\s*(\d+)',
            r'–ø–µ—Ä–µ—Ö–æ–¥\s*(?:√∏|d)?\s*(\d+)x(\d+)',
            r'–∑–∞–≥–ª—É—à–∫–∞\s*(?:√∏|d)?\s*(\d+)',
        ],
        'keywords': ['–º—É—Ñ—Ç–∞', '—Ç—Ä–æ–π–Ω–∏–∫', '–æ—Ç–≤–æ–¥', '–ø–µ—Ä–µ—Ö–æ–¥', '–∑–∞–≥–ª—É—à–∫–∞'],
        'sizes': ['50', '63', '75', '90', '110', '125'],
        'unit': '–¥–æ–Ω–∞',
        'category': 'fittings'
    },
    'valves': {
        'patterns': [
            r'–∑–∞–¥–≤–∏–∂–∫–∞\s*(?:–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω–∞—è|—á—É–≥—É–Ω–Ω–∞—è)?\s*(?:√∏|d)?\s*(\d+)',
            r'–≤–µ–Ω—Ç–∏–ª—å\s*(?:–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω—ã–π|–∑–∞–ø–æ—Ä–Ω—ã–π)?\s*(?:√∏|d)?\s*(\d+)',
            r'–∫—Ä–∞–Ω\s*(?:—à–∞—Ä–æ–≤–æ–π|–∑–∞–ø–æ—Ä–Ω—ã–π|–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω—ã–π)?\s*(?:√∏|d)?\s*(\d+)',
            r'–∫–ª–∞–ø–∞–Ω\s*(?:–æ–±—Ä–∞—Ç–Ω—ã–π|–∑–∞–ø–æ—Ä–Ω—ã–π)?\s*(?:√∏|d)?\s*(\d+)',
        ],
        'keywords': ['–∑–∞–¥–≤–∏–∂–∫–∞', '–≤–µ–Ω—Ç–∏–ª—å', '–∫—Ä–∞–Ω', '–∫–ª–∞–ø–∞–Ω'],
        'sizes': ['50', '63', '75', '80', '100', '125'],
        'unit': '–¥–æ–Ω–∞',
        'category': 'valves'
    },
    'manholes': {
        'patterns': [
            r'–ª—é–∫\s*(?:—á—É–≥—É–Ω–Ω—ã–π|—Å—Ç–∞–ª—å–Ω–æ–π|–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π)?\s*(\d+)',
            r'–ª–∞–∑\s*(?:–ª—é–∫)?\s*(\d+)',
            r'–∫—Ä—ã—à–∫–∞\s*–ª—é–∫–∞\s*(\d+)',
            r'manhole\s*(\d+)',
        ],
        'keywords': ['–ª—é–∫', '–ª–∞–∑', '–∫—Ä—ã—à–∫–∞ –ª—é–∫–∞', 'manhole'],
        'sizes': ['600', '700', '800'],
        'unit': '–¥–æ–Ω–∞',
        'category': 'manholes'
    },
    'sealing': {
        'patterns': [
            r'—É–ø–ª–æ—Ç–Ω–∏—Ç–µ–ª—å\s*(?:—Ä–µ–∑–∏–Ω–æ–≤—ã–π)?\s*(\d+)',
            r'–ø—Ä–æ–∫–ª–∞–¥–∫–∞\s*(?:—Ä–µ–∑–∏–Ω–æ–≤–∞—è)?\s*(\d+)',
            r'–≥–µ—Ä–º–µ—Ç–∏–∫\s*(?:–±–∏—Ç—É–º–Ω—ã–π|–ø–æ–ª–∏–º–µ—Ä–Ω—ã–π)?',
            r'–º–∞—Å—Ç–∏–∫–∞\s*(?:–±–∏—Ç—É–º–Ω–∞—è|–≥–∏–¥—Ä–æ–∏–∑–æ–ª—è—Ü–∏–æ–Ω–Ω–∞—è)?',
        ],
        'keywords': ['—É–ø–ª–æ—Ç–Ω–∏—Ç–µ–ª—å', '–ø—Ä–æ–∫–ª–∞–¥–∫–∞', '–≥–µ—Ä–º–µ—Ç–∏–∫', '–º–∞—Å—Ç–∏–∫–∞'],
        'sizes': ['—Å—Ç–∞–Ω–¥–∞—Ä—Ç'],
        'unit': '–∫–æ–º–ø–ª–µ–∫—Ç',
        'category': 'sealing'
    }
}

# Kolodets scheme detection keywords
KOLODETS_SCHEME_KEYWORDS = [
    '–∫–æ–ª–æ–¥–µ—Ü', '—Å–∫–≤–∞–∂–∏–Ω–∞', '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥', '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è', '–¥—Ä–µ–Ω–∞–∂',
    'well', 'water', 'sewage', 'drainage', 'manhole',
    'quduq', 'suv', 'kanalizatsiya', 'drenaj'
]

def ultra_advanced_preprocessing(image):
    """Eng ilg'or preprocessing usullari"""
    processed_images = []
    
    # Original
    processed_images.append(image)
    
    # Convert to PIL for advanced processing
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # 1. Grayscale with different methods
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    processed_images.append(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR))
    
    # 2. Adaptive histogram equalization
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    processed_images.append(cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR))
    
    # 3. Multiple noise reduction
    denoised1 = cv2.fastNlMeansDenoising(gray, h=10)
    processed_images.append(cv2.cvtColor(denoised1, cv2.COLOR_GRAY2BGR))
    
    denoised2 = cv2.bilateralFilter(gray, 9, 75, 75)
    processed_images.append(cv2.cvtColor(denoised2, cv2.COLOR_GRAY2BGR))
    
    # 4. Sharpening with different kernels
    kernel1 = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    sharpened1 = cv2.filter2D(gray, -1, kernel1)
    processed_images.append(cv2.cvtColor(sharpened1, cv2.COLOR_GRAY2BGR))
    
    kernel2 = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])
    sharpened2 = cv2.filter2D(gray, -1, kernel2)
    processed_images.append(cv2.cvtColor(sharpened2, cv2.COLOR_GRAY2BGR))
    
    # 5. Morphological operations
    kernel = np.ones((3,3), np.uint8)
    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)
    processed_images.append(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR))
    
    closed = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
    processed_images.append(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR))
    
    # 6. Edge detection
    edges = cv2.Canny(gray, 50, 150)
    processed_images.append(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR))
    
    # 7. PIL-based enhancements
    enhancer = ImageEnhance.Contrast(pil_image)
    contrasted = enhancer.enhance(2.0)
    processed_images.append(cv2.cvtColor(np.array(contrasted), cv2.COLOR_RGB2BGR))
    
    enhancer = ImageEnhance.Sharpness(pil_image)
    sharpened_pil = enhancer.enhance(2.0)
    processed_images.append(cv2.cvtColor(np.array(sharpened_pil), cv2.COLOR_RGB2BGR))
    
    # 8. Different scaling
    height, width = image.shape[:2]
    scaled_up = cv2.resize(image, (width*2, height*2), interpolation=cv2.INTER_CUBIC)
    processed_images.append(scaled_up)
    
    return processed_images

def extract_text_with_all_engines(image):
    """Barcha OCR engine'lardan foydalanish"""
    all_texts = []
    
    # EasyOCR with different parameters
    try:
        results = reader.readtext(image, detail=1, paragraph=True)
        easyocr_text = []
        for (bbox, text, confidence) in results:
            if confidence > 0.2:  # Lower threshold for better recall
                easyocr_text.append(text)
        all_texts.extend(easyocr_text)
    except Exception as e:
        print(f"EasyOCR error: {e}")
    
    # Tesseract with extensive configs
    tesseract_configs = [
        '--oem 3 --psm 6 -l rus+eng',
        '--oem 3 --psm 7 -l rus+eng',
        '--oem 3 --psm 8 -l rus+eng',
        '--oem 3 --psm 9 -l rus+eng',
        '--oem 3 --psm 10 -l rus+eng',
        '--oem 3 --psm 11 -l rus+eng',
        '--oem 3 --psm 12 -l rus+eng',
        '--oem 3 --psm 13 -l rus+eng',
        '--oem 1 --psm 6 -l rus+eng',
        '--oem 1 --psm 8 -l rus+eng',
    ]
    
    for config in tesseract_configs:
        try:
            text = pytesseract.image_to_string(image, config=config)
            if text.strip():
                all_texts.append(text)
        except Exception as e:
            print(f"Tesseract error with config {config}: {e}")
    
    return '\n'.join(all_texts)

def enhanced_blip_analysis(image):
    """Kuchaytirgan BLIP tahlili"""
    try:
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # General captioning
        inputs = blip_processor(pil_image, return_tensors="pt")
        out = blip_model.generate(**inputs, max_length=100)
        caption = blip_processor.decode(out[0], skip_special_tokens=True)
        
        # Kolodets-specific questions
        specific_questions = [
            "What construction materials are visible in this technical drawing?",
            "What pipes or tubes can you see in this scheme?",
            "Are there any concrete rings or cylinders?",
            "What metal objects or fittings are present?",
            "Is this a water well or sewage system diagram?",
            "What circular or cylindrical objects are shown?",
            "Are there any valves or connection points?",
            "What measurements or dimensions are visible?",
            "Are there any covers or lids shown?",
            "What type of construction scheme is this?"
        ]
        
        answers = []
        for question in specific_questions:
            try:
                inputs = blip_processor(pil_image, question, return_tensors="pt")
                out = blip_model.generate(**inputs, max_length=80)
                answer = blip_processor.decode(out[0], skip_special_tokens=True)
                answers.append(answer)
            except Exception as e:
                print(f"BLIP QA error for question '{question}': {e}")
                answers.append("")
        
        return {
            'caption': caption,
            'qa_results': answers,
            'questions': specific_questions
        }
    except Exception as e:
        print(f"BLIP analysis error: {e}")
        return {'caption': '', 'qa_results': [], 'questions': []}

def clip_based_classification(image):
    """CLIP model bilan klassifikatsiya"""
    try:
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # Kolodets-specific class labels
        class_labels = [
            "concrete ring", "concrete cylinder", "water well", "sewage system",
            "pipe", "tube", "fitting", "valve", "manhole cover", "bottom plate",
            "technical drawing", "construction scheme", "plumbing diagram",
            "water supply system", "drainage system"
        ]
        
        inputs = clip_processor(text=class_labels, images=pil_image, return_tensors="pt", padding=True)
        outputs = clip_model(**inputs)
        logits_per_image = outputs.logits_per_image
        probs = logits_per_image.softmax(dim=1)
        
        # Get top 5 classifications
        top_probs, top_indices = torch.topk(probs, 5)
        
        classifications = []
        for i in range(5):
            classifications.append({
                'label': class_labels[top_indices[0][i]],
                'confidence': float(top_probs[0][i])
            })
        
        return classifications
    except Exception as e:
        print(f"CLIP classification error: {e}")
        return []

def advanced_yolo_detection(image):
    """Kuchaytirgan YOLO detection"""
    try:
        # Multiple confidence thresholds
        thresholds = [0.25, 0.35, 0.45, 0.55]
        all_objects = []
        
        for thresh in thresholds:
            results = yolo_model(image, conf=thresh)
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        class_name = yolo_model.names[class_id]
                        bbox = box.xyxy[0].tolist()
                        
                        # Map YOLO classes to construction materials
                        material_mapping = {
                            'bottle': '–¢—Ä—É–±–∞ –ü–ù–î',
                            'cup': '–ú—É—Ñ—Ç–∞ —Å–æ–µ–¥–∏–Ω–∏—Ç–µ–ª—å–Ω–∞—è',
                            'bowl': '–ó–∞–≥–ª—É—à–∫–∞',
                            'cell phone': '–õ—é–∫',
                            'laptop': '–°—Ö–µ–º–∞',
                            'book': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è',
                            'scissors': '–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç',
                            'spoon': '–§–∏—Ç–∏–Ω–≥',
                            'knife': '–£–ø–ª–æ—Ç–Ω–∏—Ç–µ–ª—å'
                        }
                        
                        if class_name in material_mapping:
                            all_objects.append({
                                'class': class_name,
                                'material': material_mapping[class_name],
                                'confidence': confidence,
                                'bbox': bbox,
                                'threshold': thresh
                            })
        
        # Remove duplicates based on bbox overlap
        unique_objects = []
        for obj in all_objects:
            is_duplicate = False
            for existing in unique_objects:
                if calculate_iou(obj['bbox'], existing['bbox']) > 0.5:
                    if obj['confidence'] > existing['confidence']:
                        unique_objects.remove(existing)
                    else:
                        is_duplicate = True
                    break
            if not is_duplicate:
                unique_objects.append(obj)
        
        return unique_objects
    except Exception as e:
        print(f"YOLO detection error: {e}")
        return []

def calculate_iou(box1, box2):
    """Intersection over Union hisoblash"""
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    # Intersection area
    inter_x_min = max(x1_min, x2_min)
    inter_y_min = max(y1_min, y2_min)
    inter_x_max = min(x1_max, x2_max)
    inter_y_max = min(y1_max, y2_max)
    
    if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
        return 0.0
    
    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
    
    # Union area
    area1 = (x1_max - x1_min) * (y1_max - y1_min)
    area2 = (x2_max - x2_min) * (y2_max - y2_min)
    union_area = area1 + area2 - inter_area
    
    return inter_area / union_area if union_area > 0 else 0.0

def intelligent_material_extraction(combined_text, blip_results, clip_results, yolo_objects):
    """Aqlli material extraction"""
    materials = []
    
    # Check if it's a kolodets scheme
    is_kolodets = any(keyword in combined_text.lower() for keyword in KOLODETS_SCHEME_KEYWORDS)
    if not is_kolodets:
        # Check BLIP results
        blip_text = ' '.join([blip_results.get('caption', '')] + blip_results.get('qa_results', []))
        is_kolodets = any(keyword in blip_text.lower() for keyword in KOLODETS_SCHEME_KEYWORDS)
    
    if not is_kolodets:
        # Check CLIP results
        kolodets_labels = ['water well', 'sewage system', 'plumbing diagram', 'water supply system', 'drainage system']
        is_kolodets = any(result['label'] in kolodets_labels and result['confidence'] > 0.3 for result in clip_results)
    
    # Use specialized patterns if it's a kolodets scheme
    pattern_source = KOLODETS_MATERIALS if is_kolodets else CONSTRUCTION_MATERIALS
    
    # Text-based extraction
    text_materials = extract_materials_from_enhanced_text(combined_text, pattern_source)
    materials.extend(text_materials)
    
    # BLIP results analysis
    blip_text = blip_results.get('caption', '') + ' ' + ' '.join(blip_results.get('qa_results', []))
    blip_materials = extract_materials_from_enhanced_text(blip_text, pattern_source)
    materials.extend(blip_materials)
    
    # YOLO to materials mapping
    for obj in yolo_objects:
        if 'material' in obj:
            materials.append({
                'name': obj['material'],
                'size': '–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ —Å—Ö–µ–º–µ',
                'quantity': 1,
                'category': 'detected_object',
                'unit': '–¥–æ–Ω–∞',
                'confidence': obj['confidence'],
                'source': 'yolo'
            })
    
    # Context-based enhancement
    materials = enhance_materials_with_context(materials, combined_text, is_kolodets)
    
    # Remove duplicates and improve accuracy
    unique_materials = remove_duplicates_and_improve(materials)
    
    return unique_materials, is_kolodets

def extract_materials_from_enhanced_text(text, pattern_source):
    """Kuchaytirgan text parsing"""
    materials = []
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if len(line) < 2:
            continue
            
        line_lower = line.lower()
        
        for category, data in pattern_source.items():
            # Pattern matching with improved accuracy
            for pattern in data['patterns']:
                matches = re.finditer(pattern, line_lower, re.IGNORECASE)
                for match in matches:
                    material_name = match.group(0).title()
                    size = ""
                    quantity = 1
                    
                    # Enhanced size extraction
                    if match.groups():
                        size_parts = [g for g in match.groups() if g and g.isdigit()]
                        if len(size_parts) == 1:
                            size = f"√ò{size_parts[0]}–º–º"
                        elif len(size_parts) == 2:
                            size = f"{size_parts[0]}-{size_parts[1]}"
                    
                    # Enhanced quantity extraction
                    qty_patterns = [
                        r'(\d+)\s*(?:—à—Ç|—à—Ç—É–∫|–¥–æ–Ω–∞|pc|pieces|–∫–æ–º–ø–ª–µ–∫—Ç)',
                        r'–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ\s*[:-]?\s*(\d+)',
                        r'qty\s*[:-]?\s*(\d+)',
                        r'–∫[-]–≤–æ\s*[:-]?\s*(\d+)',
                        r'(\d+)\s*' + re.escape(material_name.lower())
                    ]
                    
                    for qty_pattern in qty_patterns:
                        qty_match = re.search(qty_pattern, line_lower)
                        if qty_match:
                            quantity = int(qty_match.group(1))
                            break
                    
                    # Determine unit
                    unit = data.get('unit', '–¥–æ–Ω–∞')
                    
                    materials.append({
                        'name': material_name,
                        'size': size or '–°—Ç–∞–Ω–¥–∞—Ä—Ç',
                        'quantity': quantity,
                        'category': category,
                        'unit': unit,
                        'confidence': 0.9,
                        'source': 'text_pattern'
                    })
            
            # Enhanced keyword matching
            for keyword in data['keywords']:
                if keyword in line_lower:
                    # Context-aware size detection
                    size_patterns = [
                        r'(?:' + re.escape(keyword) + r').*?(\d+)(?:[-.](\d+))?(?:\s*–º–º)?',
                        r'(\d+)(?:[-.](\d+))?\s*.*?' + re.escape(keyword),
                        r'√∏\s*(\d+).*?' + re.escape(keyword),
                        r'd\s*(\d+).*?' + re.escape(keyword)
                    ]
                    
                    size = "–°—Ç–∞–Ω–¥–∞—Ä—Ç"
                    for size_pattern in size_patterns:
                        size_match = re.search(size_pattern, line_lower)
                        if size_match:
                            if size_match.group(2):
                                size = f"{size_match.group(1)}-{size_match.group(2)}"
                            else:
                                size = f"√ò{size_match.group(1)}–º–º"
                            break
                    
                    materials.append({
                        'name': keyword.title(),
                        'size': size,
                        'quantity': 1,
                        'category': category,
                        'unit': data.get('unit', '–¥–æ–Ω–∞'),
                        'confidence': 0.7,
                        'source': 'text_keyword'
                    })
    
    return materials

def enhance_materials_with_context(materials, text, is_kolodets):
    """Kontekst asosida materiallarni yaxshilash"""
    enhanced_materials = []
    
    for material in materials:
        # Enhanced material based on context
        enhanced_material = material.copy()
        
        # If it's a kolodets scheme, adjust materials accordingly
        if is_kolodets:
            # Standard kolodets materials
            kolodets_standards = {
                '–∫–æ–ª—å—Ü–æ': {'standard_sizes': ['10-9', '15-9', '20-9'], 'typical_qty': 5},
                '–∫—Ä—ã—à–∫–∞': {'standard_sizes': ['10', '15', '20'], 'typical_qty': 1},
                '–ø–ª–∏—Ç–∞': {'standard_sizes': ['10', '15', '20'], 'typical_qty': 1},
                '—Ç—Ä—É–±–∞': {'standard_sizes': ['110', '160', '200'], 'typical_qty': 10},
                '–ª—é–∫': {'standard_sizes': ['600', '700'], 'typical_qty': 1}
            }
            
            for key, standards in kolodets_standards.items():
                if key in material['name'].lower():
                    if enhanced_material['size'] == '–°—Ç–∞–Ω–¥–∞—Ä—Ç':
                        enhanced_material['size'] = standards['standard_sizes'][0]
                    if enhanced_material['quantity'] == 1 and standards['typical_qty'] > 1:
                        enhanced_material['quantity'] = standards['typical_qty']
                    enhanced_material['confidence'] = min(enhanced_material['confidence'] + 0.1, 1.0)
        
        # Add notes based on context
        notes = []
        if '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥' in text.lower() or 'water' in text.lower():
            notes.append('–î–ª—è –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã')
        if '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è' in text.lower() or 'sewage' in text.lower():
            notes.append('–î–ª—è –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã')
        if '–¥—Ä–µ–Ω–∞–∂' in text.lower() or 'drainage' in text.lower():
            notes.append('–î–ª—è –¥—Ä–µ–Ω–∞–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã')
        
        enhanced_material['notes'] = notes
        enhanced_materials.append(enhanced_material)
    
    return enhanced_materials

def remove_duplicates_and_improve(materials):
    """Dublikatlarni o'chirish va yaxshilash"""
    # Group similar materials
    grouped = defaultdict(list)
    for material in materials:
        key = f"{material['name'].lower()}_{material['size']}"
        grouped[key].append(material)
    
    unique_materials = []
    for materials_group in grouped.values():
        if len(materials_group) == 1:
            unique_materials.append(materials_group[0])
        else:
            # Merge similar materials
            best_material = max(materials_group, key=lambda x: x['confidence'])
            total_quantity = sum(m['quantity'] for m in materials_group)
            
            best_material['quantity'] = total_quantity
            best_material['confidence'] = min(best_material['confidence'] + 0.1, 1.0)
            best_material['sources'] = list(set(m.get('source', 'unknown') for m in materials_group))
            
            unique_materials.append(best_material)
    
    # Sort by confidence and relevance
    unique_materials.sort(key=lambda x: (x['confidence'], x['quantity']), reverse=True)
    
    return unique_materials

@app.route('/detect_materials', methods=['POST'])
def detect_materials():
    try:
        print("–ó–∞–ø—É—Å–∫ —É–ª—å—Ç—Ä–∞-–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤...")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_type = request.content_type or ''
        print(f"Content-Type: {content_type}")
        
        if 'multipart/form-data' in content_type and 'file' in request.files:
            print("–û–±—Ä–∞–±–æ—Ç–∫–∞ multipart/form-data —Ñ–∞–π–ª–∞...")
            file = request.files['file']
            if file.filename == '':
                return jsonify({'success': False, 'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
            image_bytes = file.read()
            image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
            
        elif request.is_json:
            print("–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON –∑–∞–ø—Ä–æ—Å–∞...")
            if 'image_url' in request.json:
                image_url = request.json['image_url']
                response = requests.get(image_url)
                image = Image.open(BytesIO(response.content))
                image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            elif 'image_base64' in request.json:
                image_data = base64.b64decode(request.json['image_base64'])
                image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)
        else:
            return jsonify({'success': False, 'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞'}), 400

        if image is None:
            return jsonify({'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'}), 400
        
        print("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
        
        # –£–ª—å—Ç—Ä–∞-–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_images = ultra_advanced_preprocessing(image)
        print(f"–°–æ–∑–¥–∞–Ω–æ {len(processed_images)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        all_texts = []
        for i, proc_img in enumerate(processed_images):
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i+1}/{len(processed_images)}")
            text = extract_text_with_all_engines(proc_img)
            if text.strip():
                all_texts.append(text)
        
        combined_text = '\n'.join(all_texts)
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–ª–∏–Ω–∞: {len(combined_text)}")
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ BLIP
        print("–ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ BLIP...")
        blip_results = enhanced_blip_analysis(image)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ CLIP
        print("–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ CLIP...")
        clip_results = clip_based_classification(image)
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ YOLO
        print("–ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è YOLO...")
        yolo_objects = advanced_yolo_detection(image)
        
        # –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        print("–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤...")
        materials, is_kolodets_scheme = intelligent_material_extraction(
            combined_text, blip_results, clip_results, yolo_objects
        )
        
        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        overall_confidence = calculate_overall_confidence(materials, combined_text, blip_results, clip_results)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = generate_recommendations(materials, is_kolodets_scheme, overall_confidence)
        
        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ù–∞–π–¥–µ–Ω–æ {len(materials)} –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {overall_confidence:.1%}")
        
        return jsonify({
            'success': True,
            'materials': materials,
            'is_kolodets_scheme': is_kolodets_scheme,
            'overall_confidence': overall_confidence,
            'recommendations': recommendations,
            'analysis_results': {
                'detected_text': combined_text,
                'blip_analysis': blip_results,
                'clip_classification': clip_results,
                'yolo_objects': yolo_objects,
                'total_materials': len(materials),
                'processing_info': {
                    'processed_images': len(processed_images),
                    'text_length': len(combined_text),
                    'blip_caption': blip_results.get('caption', ''),
                    'clip_top_class': clip_results[0]['label'] if clip_results else 'unknown',
                    'yolo_detections': len(yolo_objects)
                }
            }
        })
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500

def calculate_overall_confidence(materials, text, blip_results, clip_results):
    """Umumiy ishonchlilik darajasini hisoblash"""
    if not materials:
        return 0.0
    
    # Material confidence average
    material_confidence = sum(m['confidence'] for m in materials) / len(materials)
    
    # Text quality score
    text_quality = min(len(text) / 1000, 1.0)  # Longer text = better quality
    
    # BLIP confidence (based on caption length and content quality)
    blip_confidence = 0.5
    if blip_results.get('caption'):
        blip_confidence = min(len(blip_results['caption']) / 100, 1.0)
    
    # CLIP confidence (top classification score)
    clip_confidence = 0.5
    if clip_results:
        clip_confidence = clip_results[0]['confidence']
    
    # Weighted average
    overall = (
        material_confidence * 0.4 +
        text_quality * 0.2 +
        blip_confidence * 0.2 +
        clip_confidence * 0.2
    )
    
    return overall

def generate_recommendations(materials, is_kolodets, confidence):
    """Tavsiyalar generatsiya qilish"""
    recommendations = []
    
    if confidence < 0.7:
        recommendations.append({
            'type': 'warning',
            'message': '–ê–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑–∞–ª –Ω–∏–∑–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Ä—É—á–Ω—É—é.',
            'suggestion': '–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª–µ–µ —á–µ—Ç–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ö–µ–º—ã.'
        })
    
    if is_kolodets:
        recommendations.append({
            'type': 'info',
            'message': '–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ö–µ–º–∞ –∫–æ–ª–æ–¥—Ü–∞ –≤–æ–¥–æ—Å–Ω–∞–±–∂–µ–Ω–∏—è/–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–∏.',
            'suggestion': '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–æ—Ä–º–∞—Ç–∏–≤–∞–º –°–ù–∏–ü.'
        })
        
        # Check for essential kolodets materials
        essential_materials = ['–∫–æ–ª—å—Ü–æ', '–∫—Ä—ã—à–∫–∞', '–ª—é–∫', '—Ç—Ä—É–±–∞']
        found_essential = [mat for mat in materials if any(ess in mat['name'].lower() for ess in essential_materials)]
        
        if len(found_essential) < 3:
            recommendations.append({
                'type': 'warning',
                'message': '–ù–µ –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ–ª–æ–¥—Ü–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã.',
                'suggestion': '–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞ —Å—Ö–µ–º–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç: –∫–æ–ª—å—Ü–∞, –∫—Ä—ã—à–∫–∞, –ª—é–∫, —Ç—Ä—É–±—ã.'
            })
    
    # Material-specific recommendations
    high_quantity_materials = [m for m in materials if m['quantity'] > 10]
    if high_quantity_materials:
        recommendations.append({
            'type': 'info',
            'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–∞—Ç–µ—Ä–∏–∞–ª—ã –≤ –±–æ–ª—å—à–∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞—Ö: {", ".join([m["name"] for m in high_quantity_materials])}',
            'suggestion': '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.'
        })
    
    return recommendations

@app.route('/analyze_kolodets_scheme', methods=['POST'])
def analyze_kolodets_scheme():
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ö–µ–º –∫–æ–ª–æ–¥—Ü–µ–≤"""
    try:
        # Call the main detection function
        detection_result = detect_materials()
        
        if isinstance(detection_result, tuple):
            response_data, status_code = detection_result
            if status_code != 200:
                return detection_result
            response_data = response_data.get_json()
        else:
            response_data = detection_result.get_json()
        
        if not response_data.get('success'):
            return jsonify(response_data), 400
        
        materials = response_data['materials']
        is_kolodets = response_data['is_kolodets_scheme']
        
        # Enhanced kolodets-specific analysis
        kolodets_analysis = {
            'scheme_type': 'unknown',
            'depth_estimate': '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞',
            'diameter_estimate': '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω',
            'material_completeness': 0.0,
            'construction_feasibility': 'unknown',
            'estimated_cost': '–Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞'
        }
        
        if is_kolodets:
            # Determine scheme type
            if any('–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è' in str(m).lower() for m in materials):
                kolodets_analysis['scheme_type'] = '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π –∫–æ–ª–æ–¥–µ—Ü'
            elif any('–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥' in str(m).lower() for m in materials):
                kolodets_analysis['scheme_type'] = '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω—ã–π –∫–æ–ª–æ–¥–µ—Ü'
            elif any('–¥—Ä–µ–Ω–∞–∂' in str(m).lower() for m in materials):
                kolodets_analysis['scheme_type'] = '–¥—Ä–µ–Ω–∞–∂–Ω—ã–π –∫–æ–ª–æ–¥–µ—Ü'
            else:
                kolodets_analysis['scheme_type'] = '—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–æ–ª–æ–¥–µ—Ü'
            
            # Estimate dimensions from materials
            rings = [m for m in materials if '–∫–æ–ª—å—Ü–æ' in m['name'].lower()]
            if rings:
                ring_sizes = [m['size'] for m in rings if m['size'] != '–°—Ç–∞–Ω–¥–∞—Ä—Ç']
                if ring_sizes:
                    # Parse ring size (e.g., "10-9" means diameter 10, height 9)
                    for size in ring_sizes:
                        if '-' in size:
                            diameter, height = size.split('-')
                            kolodets_analysis['diameter_estimate'] = f"{diameter}0 —Å–º"
                            total_rings = sum(m['quantity'] for m in rings)
                            kolodets_analysis['depth_estimate'] = f"{int(height) * total_rings} —Å–º"
                            break
            
            # Check material completeness
            essential_categories = ['concrete_rings', 'concrete_covers', 'bottom_plates', 'pipes', 'manholes']
            found_categories = set(m['category'] for m in materials)
            completeness = len(found_categories.intersection(essential_categories)) / len(essential_categories)
            kolodets_analysis['material_completeness'] = completeness
            
            # Construction feasibility
            if completeness > 0.8:
                kolodets_analysis['construction_feasibility'] = '–≤—ã—Å–æ–∫–∞—è'
            elif completeness > 0.6:
                kolodets_analysis['construction_feasibility'] = '—Å—Ä–µ–¥–Ω—è—è'
            else:
                kolodets_analysis['construction_feasibility'] = '–Ω–∏–∑–∫–∞—è'
        
        # Add kolodets analysis to response
        response_data['kolodets_analysis'] = kolodets_analysis
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f"Error in kolodets scheme analysis: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500

@app.route('/get_material_specifications', methods=['POST'])
def get_material_specifications():
    """–ú–∞—Ç–µ—Ä–∏–∞–ªlar —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è—Å–∏"""
    try:
        materials = request.json.get('materials', [])
        
        specifications = []
        for material in materials:
            spec = {
                'name': material['name'],
                'size': material['size'],
                'quantity': material['quantity'],
                'unit': material['unit'],
                'technical_specs': get_technical_specifications(material),
                'suppliers': get_potential_suppliers(material),
                'price_range': get_price_range(material),
                'installation_notes': get_installation_notes(material)
            }
            specifications.append(spec)
        
        return jsonify({
            'success': True,
            'specifications': specifications,
            'total_items': len(specifications)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def get_technical_specifications(material):
    """Texnik spetsifikatsiyalar"""
    specs = {
        'standard': '–ì–û–°–¢/–°–ù–∏–ü',
        'material_type': '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
        'strength_class': '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
        'temperature_range': '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
        'pressure_rating': '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'
    }
    
    name_lower = material['name'].lower()
    
    if '–∫–æ–ª—å—Ü–æ' in name_lower:
        specs.update({
            'standard': '–ì–û–°–¢ 8020-90',
            'material_type': '–∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω',
            'strength_class': 'B15-B25',
            'temperature_range': '-40¬∞C –¥–æ +50¬∞C',
            'pressure_rating': '–¥–æ 0.1 –ú–ü–∞'
        })
    elif '—Ç—Ä—É–±–∞' in name_lower:
        specs.update({
            'standard': '–ì–û–°–¢ 18599-2001',
            'material_type': '–ø–æ–ª–∏—ç—Ç–∏–ª–µ–Ω –Ω–∏–∑–∫–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è',
            'strength_class': 'SDR 17',
            'temperature_range': '-20¬∞C –¥–æ +40¬∞C',
            'pressure_rating': '1.0 –ú–ü–∞'
        })
    elif '–ª—é–∫' in name_lower:
        specs.update({
            'standard': '–ì–û–°–¢ 3634-99',
            'material_type': '—á—É–≥—É–Ω',
            'strength_class': '–∫–ª–∞—Å—Å A15',
            'temperature_range': '-40¬∞C –¥–æ +70¬∞C',
            'pressure_rating': '–Ω–∞–≥—Ä—É–∑–∫–∞ 1.5 —Ç'
        })
    
    return specs

def get_potential_suppliers(material):
    """Potensial ta'minotchilar"""
    suppliers = [
        '–ú–µ—Å—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–∑—ã',
        '–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∏—Å—Ç—Ä–∏–±—å—é—Ç–æ—Ä—ã',
        '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏ –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ–ª–∏–π',
        '–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∏'
    ]
    
    return suppliers

def get_price_range(material):
    """Narx diapazoni"""
    # This would typically connect to a pricing database
    return {
        'min_price': '—É—Ç–æ—á–Ω–∏—Ç—å',
        'max_price': '—É—Ç–æ—á–Ω–∏—Ç—å',
        'currency': '—Å—É–º',
        'unit': material['unit'],
        'last_updated': '—Ç—Ä–µ–±—É–µ—Ç –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏'
    }

def get_installation_notes(material):
    """O'rnatish eslatmalari"""
    notes = []
    
    name_lower = material['name'].lower()
    
    if '–∫–æ–ª—å—Ü–æ' in name_lower:
        notes.extend([
            '–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—Ä–∞–Ω–∞',
            '–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç–∏ —Å—Ç—ã–∫–æ–≤',
            '–û–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –≥–∏–¥—Ä–æ–∏–∑–æ–ª—è—Ü–∏—è'
        ])
    elif '—Ç—Ä—É–±–∞' in name_lower:
        notes.extend([
            '–°–æ–±–ª—é–¥–µ–Ω–∏–µ —É–∫–ª–æ–Ω–æ–≤',
            '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å',
            '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ñ–∏—Ç–∏–Ω–≥–æ–≤'
        ])
    elif '–ª—é–∫' in name_lower:
        notes.extend([
            '–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–æ–∫—Ä—ã—Ç–∏—è',
            '–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ –¥–ª—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è',
            '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å—É—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏'
        ])
    
    return notes

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy', 
        'message': 'Ultra-Advanced AI Material Detection API is running',
        'version': '2.0.0',
        'models_loaded': {
            'easyocr': True,
            'tesseract': True,
            'blip': True,
            'clip': True,
            'yolo': True
        },
        'specialized_features': {
            'kolodets_detection': True,
            'material_specifications': True,
            'confidence_scoring': True,
            'recommendations': True
        }
    })

@app.route('/supported_materials', methods=['GET'])
def supported_materials():
    """Qo'llab-quvvatlanadigan materiallar ro'yxati"""
    return jsonify({
        'success': True,
        'kolodets_materials': list(KOLODETS_MATERIALS.keys()),
        'general_materials': list(CONSTRUCTION_MATERIALS.keys()),
        'detection_keywords': KOLODETS_SCHEME_KEYWORDS,
        'total_patterns': sum(len(data['patterns']) for data in KOLODETS_MATERIALS.values())
    })

if __name__ == '__main__':
    print("üöÄ Ultra-Advanced AI Material Detection API starting...")
    print("üéØ Specialized for Kolodets (Well) Construction Schemes")
    print("üß† Enhanced with CLIP, Advanced YOLO, and Intelligent Processing")
    
    # Windows uchun maxsus sozlamalar
    import sys
    if sys.platform == "win32":
        import os
        os.system('title Python AI Material Detection API')
    
    try:
        app.run(host='127.0.0.1', port=5001, debug=False, threaded=True)
    except Exception as e:
        print(f"‚ùå Server ishga tushirishda xatolik: {e}")
        input("Press Enter to exit...")



